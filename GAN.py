import os
import torch
import torchvision.utils as vutils
import os
from DCGAN import Generator  # å¦‚æœä½ æ˜¯å†™åœ¨main.pyé‡Œï¼Œå°±ç›´æ¥å¤åˆ¶Generatorç±»è¿›æ¥
from torchvision import transforms
from PIL import Image
from tqdm import tqdm
from cleanfid import fid

# å‚æ•°è®¾ç½®ï¼ˆæ ¹æ®è®­ç»ƒæ—¶ä¿æŒä¸€è‡´ï¼‰
nz = 100           # å™ªå£°ç»´åº¦ï¼ˆlatent vector sizeï¼‰
ngf = 64           # ç”Ÿæˆå™¨çš„ feature map åŸºæ•°
nc = 3             # å›¾åƒé€šé“æ•°ï¼ˆRGB=3ï¼‰
n_generate = 1000  # è¦ç”Ÿæˆçš„å›¾åƒæ€»æ•°é‡
batch_size = 64    # æ¯æ‰¹ç”Ÿæˆå¤šå°‘å¼ å›¾
image_size = 64    # å›¾åƒå°ºå¯¸ï¼ˆé€šå¸¸ä¸º64Ã—64ï¼‰
ngpu = 1           # GPU æ•°é‡ï¼ˆå•å¡ï¼‰
real_images_path = "/content/drive/MyDrive/VisDrone2019-Patch/awning-tricycle"
output_path = "/content/drive/MyDrive/VisDrone2019-Generate/awning-tricycle"
model_path = '/content/drive/MyDrive/VisDrone2019-Generate/Generator/awning-tricycle/netG_epoch_24.pth'
os.makedirs(output_path, exist_ok=True)

# åŠ è½½æ¨¡å‹
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
netG = Generator(nz=nz, ngf=ngf, nc=nc).to(device)
netG.load_state_dict(torch.load(model_path, map_location=device))  # ä½ ä¿å­˜çš„è·¯å¾„
netG.eval()

# ==== å›¾åƒç”Ÿæˆå¹¶ä¿å­˜ ====
transform = transforms.ToPILImage()
idx = 0
with torch.no_grad():
    for _ in tqdm(range((n_generate + batch_size - 1) // batch_size), desc="Generating"):
        current_batch = min(batch_size, n_generate - idx)
        noise = torch.randn(current_batch, nz, 1, 1, device=device)
        fake_images = netG(noise).cpu()

        for i in range(current_batch):
            img = transform((fake_images[i] + 1) / 2)  # [-1,1] â†’ [0,1]
            img.save(os.path.join(output_path, f"{idx + i:05d}.jpg"))
        idx += current_batch

print(f"\nâœ… ç”Ÿæˆå®Œæˆï¼Œå›¾åƒä¿å­˜åœ¨ï¼š{output_path}")

# ==== è®¡ç®— FID åˆ†æ•° ====
fid_score = fid.compute_fid(real_images_path, output_path, mode="clean", dataset_name=None)
print(f"\nğŸ¯ FID å¾—åˆ†ï¼ˆè¶Šä½è¶Šå¥½ï¼‰: {fid_score:.4f}")